{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objetivo\n",
    "\n",
    "Identificar as relações entre as variáveis explicativa e resposta, usando diferentes modelos. No mundo real, a detecção de fraude precisa ser feita rapidamente de modo que haja equilíbrio entre os falsos positivos e falsos negativos.\n",
    "\n",
    "Avaliação de alguns testes:\n",
    "\n",
    "1. Modelo aplicado na base completa (desbalanceado);\n",
    "\n",
    "2. Modelo aplicado em folds balanceados (undersampling e oversampling) e validados em folds originais (desbalanceados).\n",
    "\n",
    "OBS: será usado uma amostra para esse estudo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pacotes e funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import mlflow\n",
    "from mlflow.models import infer_signature\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, roc_auc_score, precision_score, recall_score, accuracy_score, average_precision_score, brier_score_loss, confusion_matrix, classification_report, ConfusionMatrixDisplay, precision_recall_curve, log_loss\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "import xgboost\n",
    "from catboost import CatBoostClassifier\n",
    "import lightgbm\n",
    "from hyperopt import fmin, tpe, Trials, hp\n",
    "from functools import partial\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install xgboost\n",
    "#!pip install catboost\n",
    "#!pip install ipywidgets\n",
    "#!jupyter nbextension enable --py widgetsnbextension\n",
    "#!pip install hyperopt\n",
    "#!pip install lightgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bases pré-processadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "treino_full = pd.read_parquet('../3.Pre_processamento/treino_pp.parquet')\n",
    "val_full = pd.read_parquet('../3.Pre_processamento/validacao_pp.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(783000, 14)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treino_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "treino = treino_full.sample(frac=.1, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78300, 14)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treino.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fraud\n",
       "0    0.91424\n",
       "1    0.08576\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treino['fraud'].value_counts()/treino.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.3665404217199164"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(0.08576/0.91424)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance_from_home</th>\n",
       "      <th>distance_from_last_transaction</th>\n",
       "      <th>ratio_to_median_purchase_price</th>\n",
       "      <th>repeat_retailer</th>\n",
       "      <th>used_chip</th>\n",
       "      <th>used_pin_number</th>\n",
       "      <th>online_order</th>\n",
       "      <th>fraud</th>\n",
       "      <th>log_DFH</th>\n",
       "      <th>log_DFLT</th>\n",
       "      <th>log_RTMPP</th>\n",
       "      <th>log_DFH_padro</th>\n",
       "      <th>log_DFLT_padro</th>\n",
       "      <th>log_RTMPP_padro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>275847</th>\n",
       "      <td>3.132982</td>\n",
       "      <td>0.136709</td>\n",
       "      <td>0.905399</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.141985</td>\n",
       "      <td>-1.989898</td>\n",
       "      <td>-0.099380</td>\n",
       "      <td>-0.826670</td>\n",
       "      <td>-1.104029</td>\n",
       "      <td>-0.089090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287479</th>\n",
       "      <td>20.395077</td>\n",
       "      <td>0.805684</td>\n",
       "      <td>2.582759</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.015294</td>\n",
       "      <td>-0.216063</td>\n",
       "      <td>0.948858</td>\n",
       "      <td>0.510707</td>\n",
       "      <td>-0.118208</td>\n",
       "      <td>0.865273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737603</th>\n",
       "      <td>55.317530</td>\n",
       "      <td>2.933958</td>\n",
       "      <td>0.573614</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.013090</td>\n",
       "      <td>1.076352</td>\n",
       "      <td>-0.555799</td>\n",
       "      <td>1.223046</td>\n",
       "      <td>0.600060</td>\n",
       "      <td>-0.504634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136843</th>\n",
       "      <td>378.405321</td>\n",
       "      <td>1.208453</td>\n",
       "      <td>2.182680</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.935966</td>\n",
       "      <td>0.189341</td>\n",
       "      <td>0.780553</td>\n",
       "      <td>2.595811</td>\n",
       "      <td>0.107098</td>\n",
       "      <td>0.712041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313895</th>\n",
       "      <td>9.967356</td>\n",
       "      <td>1.027505</td>\n",
       "      <td>0.781084</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.299315</td>\n",
       "      <td>0.027133</td>\n",
       "      <td>-0.247073</td>\n",
       "      <td>-0.000438</td>\n",
       "      <td>0.016950</td>\n",
       "      <td>-0.223556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        distance_from_home  distance_from_last_transaction  \\\n",
       "275847            3.132982                        0.136709   \n",
       "287479           20.395077                        0.805684   \n",
       "737603           55.317530                        2.933958   \n",
       "136843          378.405321                        1.208453   \n",
       "313895            9.967356                        1.027505   \n",
       "\n",
       "        ratio_to_median_purchase_price  repeat_retailer  used_chip  \\\n",
       "275847                        0.905399                1          0   \n",
       "287479                        2.582759                1          0   \n",
       "737603                        0.573614                1          0   \n",
       "136843                        2.182680                1          0   \n",
       "313895                        0.781084                1          0   \n",
       "\n",
       "        used_pin_number  online_order  fraud   log_DFH  log_DFLT  log_RTMPP  \\\n",
       "275847                0             1      0  1.141985 -1.989898  -0.099380   \n",
       "287479                1             1      0  3.015294 -0.216063   0.948858   \n",
       "737603                0             1      0  4.013090  1.076352  -0.555799   \n",
       "136843                0             1      1  5.935966  0.189341   0.780553   \n",
       "313895                0             1      0  2.299315  0.027133  -0.247073   \n",
       "\n",
       "        log_DFH_padro  log_DFLT_padro  log_RTMPP_padro  \n",
       "275847      -0.826670       -1.104029        -0.089090  \n",
       "287479       0.510707       -0.118208         0.865273  \n",
       "737603       1.223046        0.600060        -0.504634  \n",
       "136843       2.595811        0.107098         0.712041  \n",
       "313895      -0.000438        0.016950        -0.223556  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treino.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Somente as variáveis com IV até 0.5, pois existem poucas variáveis na base\n",
    "colunas = ['repeat_retailer','used_chip','used_pin_number','online_order','log_DFH_padro','log_DFLT_padro']\n",
    "\n",
    "X_treino = treino[colunas]\n",
    "y_treino = treino['fraud']\n",
    "\n",
    "X_val = val_full[colunas]\n",
    "y_val = val_full['fraud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.08575989782886334, 0.0874017094017094)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_treino.sum()/len(y_treino), y_val.sum()/len(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criação do experimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#experiment = mlflow.create_experiment(name = 'Modelos',\n",
    "#                                      artifact_location = 'Artf_Modelos',\n",
    "#                                      tags = {'Environment': 'Development', 'Version': '1.0.0'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'189457669412080989'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'189457669412080989'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment = mlflow.set_experiment(experiment_id = '189457669412080989')\n",
    "experiment.experiment_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regressão logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://bookdown.org/egarpor/PM-UC3M/glm-deviance.html\n",
    "# https://stats.stackexchange.com/questions/108995/interpreting-residual-and-null-deviance-in-glm-r\n",
    "\n",
    "LR = sm.GLM(y_treino, sm.add_constant(X_treino), family=sm.families.Binomial())\n",
    "LR_results = LR.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>fraud</td>      <th>  No. Observations:  </th>  <td> 78300</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>GLM</td>       <th>  Df Residuals:      </th>  <td> 78293</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>        <td>Binomial</td>     <th>  Df Model:          </th>  <td>     6</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>         <td>Logit</td>      <th>  Scale:             </th> <td>  1.0000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -19206.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Wed, 19 Mar 2025</td> <th>  Deviance:          </th> <td>  38413.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>21:16:38</td>     <th>  Pearson chi2:      </th> <td>7.11e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>          <td>9</td>        <th>  Pseudo R-squ. (CS):</th>  <td>0.09031</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "         <td></td>            <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>           <td>   -2.8151</td> <td>    0.068</td> <td>  -41.415</td> <td> 0.000</td> <td>   -2.948</td> <td>   -2.682</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>repeat_retailer</th> <td>   -1.5955</td> <td>    0.054</td> <td>  -29.725</td> <td> 0.000</td> <td>   -1.701</td> <td>   -1.490</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>used_chip</th>       <td>   -0.5194</td> <td>    0.030</td> <td>  -17.221</td> <td> 0.000</td> <td>   -0.579</td> <td>   -0.460</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>used_pin_number</th> <td>   -3.6776</td> <td>    0.210</td> <td>  -17.543</td> <td> 0.000</td> <td>   -4.089</td> <td>   -3.267</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>online_order</th>    <td>    2.4200</td> <td>    0.054</td> <td>   44.405</td> <td> 0.000</td> <td>    2.313</td> <td>    2.527</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>log_DFH_padro</th>   <td>    0.7188</td> <td>    0.017</td> <td>   43.251</td> <td> 0.000</td> <td>    0.686</td> <td>    0.751</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>log_DFLT_padro</th>  <td>    0.2127</td> <td>    0.013</td> <td>   15.791</td> <td> 0.000</td> <td>    0.186</td> <td>    0.239</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &      fraud       & \\textbf{  No. Observations:  } &    78300    \\\\\n",
       "\\textbf{Model:}            &       GLM        & \\textbf{  Df Residuals:      } &    78293    \\\\\n",
       "\\textbf{Model Family:}     &     Binomial     & \\textbf{  Df Model:          } &        6    \\\\\n",
       "\\textbf{Link Function:}    &      Logit       & \\textbf{  Scale:             } &    1.0000   \\\\\n",
       "\\textbf{Method:}           &       IRLS       & \\textbf{  Log-Likelihood:    } &   -19206.   \\\\\n",
       "\\textbf{Date:}             & Wed, 19 Mar 2025 & \\textbf{  Deviance:          } &    38413.   \\\\\n",
       "\\textbf{Time:}             &     21:16:38     & \\textbf{  Pearson chi2:      } &  7.11e+04   \\\\\n",
       "\\textbf{No. Iterations:}   &        9         & \\textbf{  Pseudo R-squ. (CS):} &  0.09031    \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                           & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const}             &      -2.8151  &        0.068     &   -41.415  &         0.000        &       -2.948    &       -2.682     \\\\\n",
       "\\textbf{repeat\\_retailer}  &      -1.5955  &        0.054     &   -29.725  &         0.000        &       -1.701    &       -1.490     \\\\\n",
       "\\textbf{used\\_chip}        &      -0.5194  &        0.030     &   -17.221  &         0.000        &       -0.579    &       -0.460     \\\\\n",
       "\\textbf{used\\_pin\\_number} &      -3.6776  &        0.210     &   -17.543  &         0.000        &       -4.089    &       -3.267     \\\\\n",
       "\\textbf{online\\_order}     &       2.4200  &        0.054     &    44.405  &         0.000        &        2.313    &        2.527     \\\\\n",
       "\\textbf{log\\_DFH\\_padro}   &       0.7188  &        0.017     &    43.251  &         0.000        &        0.686    &        0.751     \\\\\n",
       "\\textbf{log\\_DFLT\\_padro}  &       0.2127  &        0.013     &    15.791  &         0.000        &        0.186    &        0.239     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{Generalized Linear Model Regression Results}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:                  fraud   No. Observations:                78300\n",
       "Model:                            GLM   Df Residuals:                    78293\n",
       "Model Family:                Binomial   Df Model:                            6\n",
       "Link Function:                  Logit   Scale:                          1.0000\n",
       "Method:                          IRLS   Log-Likelihood:                -19206.\n",
       "Date:                Wed, 19 Mar 2025   Deviance:                       38413.\n",
       "Time:                        21:16:38   Pearson chi2:                 7.11e+04\n",
       "No. Iterations:                     9   Pseudo R-squ. (CS):            0.09031\n",
       "Covariance Type:            nonrobust                                         \n",
       "===================================================================================\n",
       "                      coef    std err          z      P>|z|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------\n",
       "const              -2.8151      0.068    -41.415      0.000      -2.948      -2.682\n",
       "repeat_retailer    -1.5955      0.054    -29.725      0.000      -1.701      -1.490\n",
       "used_chip          -0.5194      0.030    -17.221      0.000      -0.579      -0.460\n",
       "used_pin_number    -3.6776      0.210    -17.543      0.000      -4.089      -3.267\n",
       "online_order        2.4200      0.054     44.405      0.000       2.313       2.527\n",
       "log_DFH_padro       0.7188      0.017     43.251      0.000       0.686       0.751\n",
       "log_DFLT_padro      0.2127      0.013     15.791      0.000       0.186       0.239\n",
       "===================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função objetivo\n",
    "\n",
    "Função objetivo para ser minimizada e encontrar o melhor conjunto de hiperparâmetros com o uso de validação cruzada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_objetivo_CV(parametros, modelo, folds, expr, X, y):\n",
    "    # função objetivo para \"minimizar\", mas dependendo da métrica de interesse, na realidade, é maximizar \n",
    "    # parametros é o espaço paramétrico a ser explorado\n",
    "    # expr é uma string que representa o id do experimento que foi criado\n",
    "    # modelo é uma string de qual modelo será rodado: Random Forest ou XGBoost\n",
    "    # folds é um int que diz quantos folds de validação serão usados\n",
    "    # X e y são as bases que serão aplicadas o cross-validation\n",
    "\n",
    "    # O output é o valor do score a ser minimizado/maximizado\n",
    "    \n",
    "    with mlflow.start_run(nested = True, experiment_id=expr) as run:\n",
    "\n",
    "        SKF = StratifiedKFold(n_splits = folds, shuffle=True, random_state=1234)\n",
    "\n",
    "        if modelo == 'RF':\n",
    "            clf = RandomForestClassifier(**parametros) \n",
    "            clf.fit(X, y)\n",
    "        elif modelo == 'XGB':\n",
    "            clf = xgboost.XGBClassifier(**parametros)\n",
    "            clf.fit(X, y)\n",
    "        elif modelo == 'CAT':\n",
    "            clf = CatBoostClassifier(**parametros)\n",
    "            clf.fit(X, y)\n",
    "        elif modelo == 'LGBM':\n",
    "            clf = lightgbm.LGBMClassifier(**parametros)\n",
    "            clf.fit(X, y)\n",
    "        \n",
    "        score = cross_val_score(estimator = clf, X = X, y = y, cv = SKF, scoring='neg_log_loss').mean()\n",
    "\n",
    "        # Log de parâmetros e métricas\n",
    "\n",
    "        mlflow.log_params(clf.get_params())\n",
    "        mlflow.log_metric('average_precision_cv', cross_val_score(estimator = clf, X = X, y = y, cv = SKF, scoring='average_precision').mean())\n",
    "        mlflow.log_metric('roc_auc_cv', cross_val_score(estimator = clf, X = X, y = y, cv = SKF, scoring='roc_auc').mean())\n",
    "        mlflow.log_metric('neg_brier_score_cv', cross_val_score(estimator = clf, X = X, y = y, cv = SKF, scoring='neg_brier_score').mean())\n",
    "        mlflow.log_metric('neg_log_loss_cv', cross_val_score(estimator = clf, X = X, y = y, cv = SKF, scoring='neg_log_loss').mean())\n",
    "        \n",
    "        signature = infer_signature(X, clf.predict_proba(X))\n",
    "        mlflow.sklearn.log_model(clf, signature=signature, artifact_path='modelo')\n",
    "\n",
    "    return -score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hugo/Documents/Git_GitHub/Estudo_Fraude_CC/vFraude_CC/lib/python3.12/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    with mlflow.start_run(run_name = 'RF_AllVars_Amostra', experiment_id = experiment.experiment_id) as run: \n",
    "\n",
    "        rf = RandomForestClassifier()\n",
    "        rf.fit(X_treino, y_treino)\n",
    "\n",
    "        # Log dos parâmetros do modelo\n",
    "        mlflow.log_params(rf.get_params())\n",
    "\n",
    "        # Log das métricas na base de TREINO\n",
    "        mlflow.log_metric('AUC_PR_Treino', average_precision_score(y_treino, rf.predict_proba(X_treino)[:,1]))\n",
    "        mlflow.log_metric('AUC_ROC_Treino', roc_auc_score(y_treino, rf.predict_proba(X_treino)[:,1]))\n",
    "        mlflow.log_metric('BS_Treino', brier_score_loss(y_treino, rf.predict_proba(X_treino)[:,1]))\n",
    "        mlflow.log_metric('Log_Loss_Treino', log_loss(y_treino, rf.predict_proba(X_treino)[:,1], normalize=True))\n",
    "\n",
    "        # OBS: o ponto de corte utilizado é o 0.5 (ainda não otimizamos esse ponto)\n",
    "        #mlflow.log_metric('F1_Treino', f1_score(y_treino, rf.predict(X_treino)))\n",
    "        #mlflow.log_metric('Precision_Treino', precision_score(y_treino, rf.predict(X_treino)))\n",
    "        #mlflow.log_metric('Recall_Treino', recall_score(y_treino, rf.predict(X_treino)))\n",
    "        #mlflow.log_metric('Acuracia_Treino', accuracy_score(y_treino, rf.predict(X_treino)))\n",
    "\n",
    "        # Log das métricas na base de VALIDAÇÃO\n",
    "        mlflow.log_metric('AUC_PR_Val', average_precision_score(y_val, rf.predict_proba(X_val)[:,1]))\n",
    "        mlflow.log_metric('AUC_ROC_Val', roc_auc_score(y_val, rf.predict_proba(X_val)[:,1]))\n",
    "        mlflow.log_metric('BS_Val', brier_score_loss(y_val, rf.predict_proba(X_val)[:,1]))\n",
    "        mlflow.log_metric('Log_Loss_Val', log_loss(y_val, rf.predict_proba(X_val)[:,1], normalize=True))\n",
    "\n",
    "        # OBS: o ponto de corte utilizado é o 0.5 (ainda não otimizamos esse ponto)\n",
    "        #mlflow.log_metric('F1_Val', f1_score(y_val, rf.predict(X_val)))\n",
    "        #mlflow.log_metric('Precision_Val', precision_score(y_val, rf.predict(X_val)))\n",
    "        #mlflow.log_metric('Recall_Val', recall_score(y_val, rf.predict(X_val)))\n",
    "        #mlflow.log_metric('Acuracia_Val', accuracy_score(y_val, rf.predict(X_val)))\n",
    "        \n",
    "        # Log do schema das variáveis do modelo e do modelo\n",
    "        signature = infer_signature(X_treino, rf.predict_proba(X_treino))\n",
    "        mlflow.sklearn.log_model(rf, signature=signature, artifact_path='modelo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hugo/Documents/Git_GitHub/Estudo_Fraude_CC/vFraude_CC/lib/python3.12/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/25 [28:45<11:30:13, 1725.54s/trial, best loss: 0.04148710138585226]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hugo/Documents/Git_GitHub/Estudo_Fraude_CC/vFraude_CC/lib/python3.12/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    #test_imbalanced = [{0: len(y_treino2)/(2*np.bincount(y_treino2))[0], 1:len(y_teste2)/(2*np.bincount(y_teste2))[1]}, {0: 1, 1:1}]\n",
    "    \n",
    "    space = {\n",
    "        \"n_estimators\": hp.choice('n_estimators', np.arange(10, 500, dtype=int)),\n",
    "        \"max_depth\": hp.choice('max_depth', np.arange(10, 300, dtype=int)),\n",
    "        \"min_samples_leaf\": hp.choice('min_samples_leaf', np.arange(200, 500, dtype=int)),\n",
    "        \"min_samples_split\": hp.choice('min_samples_split', np.arange(200, 500, dtype=int)),\n",
    "        \"criterion\": hp.choice(\"criterion\", ['gini', 'entropy', 'log_loss']),\n",
    "        \"class_weight\": hp.choice(\"class_weight\", ['balanced', 'balanced_subsample', None]) \n",
    "    }\n",
    "    \n",
    "    with mlflow.start_run(run_name = 'RF_AllVars_Amostra_CV', experiment_id=experiment.experiment_id) as run:\n",
    "        best_params = fmin(\n",
    "            fn = partial(\n",
    "                func_objetivo_CV,\n",
    "                expr = experiment.experiment_id,\n",
    "                modelo = 'RF',\n",
    "                X = X_treino,\n",
    "                y = y_treino,\n",
    "                folds = 3\n",
    "            ),\n",
    "            space = space,\n",
    "            algo = tpe.suggest,\n",
    "            max_evals = 25,\n",
    "            trials = Trials(),\n",
    "            timeout = 10\n",
    "        )\n",
    "\n",
    "        if best_params['criterion'] == 0:\n",
    "            best_params['criterion'] = 'gini'\n",
    "        elif best_params['criterion'] == 1:\n",
    "            best_params['criterion'] = 'entropy'\n",
    "        else:\n",
    "            best_params['criterion'] = 'log_loss'\n",
    "            \n",
    "\n",
    "        if best_params['class_weight'] == 0:\n",
    "            best_params['class_weight'] = 'balanced'\n",
    "        elif best_params['class_weight'] == 1:\n",
    "            best_params['class_weight'] = 'balanced_subsample'\n",
    "        else:\n",
    "            best_params['class_weight'] = None\n",
    "        \n",
    "        # Identificado o melhor conjunto de hiperparâmetros, treina o modelo com toda a base de treino e metrifica os escores na base de validação\n",
    "\n",
    "        clf = RandomForestClassifier(**best_params)\n",
    "        clf.fit(X_treino, y_treino)\n",
    "                   \n",
    "        mlflow.log_params(clf.get_params())\n",
    "        mlflow.log_metric('AUC_PR_Val', average_precision_score(y_val, clf.predict_proba(X_val)[:,1]))\n",
    "        mlflow.log_metric('Log_Loss_Val', log_loss(y_val, clf.predict_proba(X_val)[:,1], normalize=True))\n",
    "        mlflow.log_metric('AUC_ROC_Val', roc_auc_score(y_val, clf.predict_proba(X_val)[:,1]))\n",
    "        mlflow.log_metric('BS_Val', brier_score_loss(y_val, clf.predict_proba(X_val)[:,1]))\n",
    "\n",
    "        # Log das métricas na base de TREINO\n",
    "        mlflow.log_metric('AUC_PR_Treino', average_precision_score(y_treino, clf.predict_proba(X_treino)[:,1]))\n",
    "        mlflow.log_metric('AUC_ROC_Treino', roc_auc_score(y_treino, clf.predict_proba(X_treino)[:,1]))\n",
    "        mlflow.log_metric('BS_Treino', brier_score_loss(y_treino, clf.predict_proba(X_treino)[:,1]))\n",
    "        mlflow.log_metric('Log_Loss_Treino', log_loss(y_treino, clf.predict_proba(X_treino)[:,1], normalize=True))\n",
    "\n",
    "        signature = infer_signature(X_treino, clf.predict_proba(X_treino))\n",
    "        mlflow.sklearn.log_model(clf, signature=signature, artifact_path='modelo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base parcial IV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hugo/Documents/Git_GitHub/Estudo_Fraude_CC/vFraude_CC/lib/python3.12/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/25 [09:06<3:38:37, 546.55s/trial, best loss: 0.23410350369495644]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hugo/Documents/Git_GitHub/Estudo_Fraude_CC/vFraude_CC/lib/python3.12/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    #test_imbalanced = [{0: len(y_treino2)/(2*np.bincount(y_treino2))[0], 1:len(y_teste2)/(2*np.bincount(y_teste2))[1]}, {0: 1, 1:1}]\n",
    "    \n",
    "    space = {\n",
    "        \"n_estimators\": hp.choice('n_estimators', np.arange(10, 500, dtype=int)),\n",
    "        \"max_depth\": hp.choice('max_depth', np.arange(10, 300, dtype=int)),\n",
    "        \"min_samples_leaf\": hp.choice('min_samples_leaf', np.arange(200, 500, dtype=int)),\n",
    "        \"min_samples_split\": hp.choice('min_samples_split', np.arange(200, 500, dtype=int)),\n",
    "        \"criterion\": hp.choice(\"criterion\", ['gini', 'entropy', 'log_loss']),\n",
    "        \"class_weight\": hp.choice(\"class_weight\", ['balanced', 'balanced_subsample', None]) \n",
    "    }\n",
    "    \n",
    "    with mlflow.start_run(run_name = 'RF_IVVars_Amostra_CV', experiment_id=experiment.experiment_id) as run:\n",
    "        best_params = fmin(\n",
    "            fn = partial(\n",
    "                func_objetivo_CV,\n",
    "                expr = experiment.experiment_id,\n",
    "                modelo = 'RF',\n",
    "                X = X_treino_IV,\n",
    "                y = y_treino,\n",
    "                folds = 3\n",
    "            ),\n",
    "            space = space,\n",
    "            algo = tpe.suggest,\n",
    "            max_evals = 25,\n",
    "            trials = Trials(),\n",
    "            timeout = 10\n",
    "        )\n",
    "\n",
    "        if best_params['criterion'] == 0:\n",
    "            best_params['criterion'] = 'gini'\n",
    "        elif best_params['criterion'] == 1:\n",
    "            best_params['criterion'] = 'entropy'\n",
    "        else:\n",
    "            best_params['criterion'] = 'log_loss'\n",
    "            \n",
    "\n",
    "        if best_params['class_weight'] == 0:\n",
    "            best_params['class_weight'] = 'balanced'\n",
    "        elif best_params['class_weight'] == 1:\n",
    "            best_params['class_weight'] = 'balanced_subsample'\n",
    "        else:\n",
    "            best_params['class_weight'] = None\n",
    "        \n",
    "        # Identificado o melhor conjunto de hiperparâmetros, treina o modelo com toda a base de treino e metrifica os escores na base de validação\n",
    "\n",
    "        clf = RandomForestClassifier(**best_params)\n",
    "        clf.fit(X_treino_IV, y_treino)\n",
    "                   \n",
    "        mlflow.log_params(clf.get_params())\n",
    "        mlflow.log_metric('AUC_PR_Val', average_precision_score(y_val, clf.predict_proba(X_val_IV)[:,1]))\n",
    "        mlflow.log_metric('Log_Loss_Val', log_loss(y_val, clf.predict_proba(X_val_IV)[:,1], normalize=True))\n",
    "        mlflow.log_metric('AUC_ROC_Val', roc_auc_score(y_val, clf.predict_proba(X_val_IV)[:,1]))\n",
    "        mlflow.log_metric('BS_Val', brier_score_loss(y_val, clf.predict_proba(X_val_IV)[:,1]))\n",
    "\n",
    "        # Log das métricas na base de TREINO\n",
    "        mlflow.log_metric('AUC_PR_Treino', average_precision_score(y_treino, clf.predict_proba(X_treino_IV)[:,1]))\n",
    "        mlflow.log_metric('AUC_ROC_Treino', roc_auc_score(y_treino, clf.predict_proba(X_treino_IV)[:,1]))\n",
    "        mlflow.log_metric('BS_Treino', brier_score_loss(y_treino, clf.predict_proba(X_treino_IV)[:,1]))\n",
    "        mlflow.log_metric('Log_Loss_Treino', log_loss(y_treino, clf.predict_proba(X_treino_IV)[:,1], normalize=True))\n",
    "\n",
    "        signature = infer_signature(X_treino_IV, clf.predict_proba(X_treino_IV))\n",
    "        mlflow.sklearn.log_model(clf, signature=signature, artifact_path='modelo')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vFraude_CC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
