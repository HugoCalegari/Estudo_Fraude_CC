{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objetivo\n",
    "\n",
    "Identificar as relações entre as variáveis explicativa e resposta, usando diferentes modelos. No mundo real, a detecção de fraude precisa ser feita rapidamente de modo que haja equilíbrio entre os falsos positivos e falsos negativos.\n",
    "\n",
    "Avaliação de alguns testes:\n",
    "\n",
    "1. Modelo aplicado na base completa (desbalanceado);\n",
    "\n",
    "2. Modelo aplicado em folds balanceados (undersampling e oversampling) e validados em folds originais (desbalanceados)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pacotes e funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import mlflow\n",
    "from mlflow.models import infer_signature\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, roc_auc_score, precision_score, recall_score, accuracy_score, average_precision_score, brier_score_loss, confusion_matrix, classification_report, ConfusionMatrixDisplay, precision_recall_curve, log_loss\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "import xgboost\n",
    "from catboost import CatBoostClassifier\n",
    "from hyperopt import fmin, tpe, Trials, hp\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install xgboost\n",
    "#!pip install catboost\n",
    "#!pip install ipywidgets\n",
    "#!jupyter nbextension enable --py widgetsnbextension\n",
    "#!pip install hyperopt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bases pré-processadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "treino = pd.read_parquet('../3.Pre_processamento/treino_pp.parquet')\n",
    "val = pd.read_parquet('../3.Pre_processamento/validacao_pp.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance_from_home</th>\n",
       "      <th>distance_from_last_transaction</th>\n",
       "      <th>ratio_to_median_purchase_price</th>\n",
       "      <th>repeat_retailer</th>\n",
       "      <th>used_chip</th>\n",
       "      <th>used_pin_number</th>\n",
       "      <th>online_order</th>\n",
       "      <th>fraud</th>\n",
       "      <th>log_DFH</th>\n",
       "      <th>log_DFLT</th>\n",
       "      <th>log_RTMPP</th>\n",
       "      <th>log_DFH_padro</th>\n",
       "      <th>log_DFLT_padro</th>\n",
       "      <th>log_RTMPP_padro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.689623</td>\n",
       "      <td>0.347200</td>\n",
       "      <td>1.105109</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.738644</td>\n",
       "      <td>-1.057854</td>\n",
       "      <td>0.099944</td>\n",
       "      <td>-0.400708</td>\n",
       "      <td>-0.586039</td>\n",
       "      <td>0.092383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58.380209</td>\n",
       "      <td>0.124193</td>\n",
       "      <td>0.334676</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.066977</td>\n",
       "      <td>-2.085922</td>\n",
       "      <td>-1.094593</td>\n",
       "      <td>1.261517</td>\n",
       "      <td>-1.157395</td>\n",
       "      <td>-0.995176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.729568</td>\n",
       "      <td>2.809812</td>\n",
       "      <td>0.352684</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.078674</td>\n",
       "      <td>1.033118</td>\n",
       "      <td>-1.042184</td>\n",
       "      <td>0.555955</td>\n",
       "      <td>0.576032</td>\n",
       "      <td>-0.947461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49.862629</td>\n",
       "      <td>1.040213</td>\n",
       "      <td>0.943036</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.909272</td>\n",
       "      <td>0.039426</td>\n",
       "      <td>-0.058651</td>\n",
       "      <td>1.148930</td>\n",
       "      <td>0.023781</td>\n",
       "      <td>-0.052008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.585701</td>\n",
       "      <td>3.446598</td>\n",
       "      <td>1.715601</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.609018</td>\n",
       "      <td>1.237388</td>\n",
       "      <td>0.539764</td>\n",
       "      <td>0.220662</td>\n",
       "      <td>0.689556</td>\n",
       "      <td>0.492815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   distance_from_home  distance_from_last_transaction  \\\n",
       "0            5.689623                        0.347200   \n",
       "1           58.380209                        0.124193   \n",
       "2           21.729568                        2.809812   \n",
       "3           49.862629                        1.040213   \n",
       "4           13.585701                        3.446598   \n",
       "\n",
       "   ratio_to_median_purchase_price  repeat_retailer  used_chip  \\\n",
       "0                        1.105109                1          0   \n",
       "1                        0.334676                1          0   \n",
       "2                        0.352684                1          0   \n",
       "3                        0.943036                1          0   \n",
       "4                        1.715601                1          0   \n",
       "\n",
       "   used_pin_number  online_order  fraud   log_DFH  log_DFLT  log_RTMPP  \\\n",
       "0                0             1      0  1.738644 -1.057854   0.099944   \n",
       "1                0             1      0  4.066977 -2.085922  -1.094593   \n",
       "2                0             0      0  3.078674  1.033118  -1.042184   \n",
       "3                0             1      0  3.909272  0.039426  -0.058651   \n",
       "4                0             0      0  2.609018  1.237388   0.539764   \n",
       "\n",
       "   log_DFH_padro  log_DFLT_padro  log_RTMPP_padro  \n",
       "0      -0.400708       -0.586039         0.092383  \n",
       "1       1.261517       -1.157395        -0.995176  \n",
       "2       0.555955        0.576032        -0.947461  \n",
       "3       1.148930        0.023781        -0.052008  \n",
       "4       0.220662        0.689556         0.492815  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treino.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas = ['repeat_retailer','used_chip','used_pin_number','online_order','log_DFH_padro','log_DFLT_padro','log_RTMPP_padro']\n",
    "\n",
    "X_treino = treino[colunas]\n",
    "y_treino = treino['fraud']\n",
    "\n",
    "X_val = val[colunas]\n",
    "y_val = val['fraud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.08740357598978289, 0.0874017094017094)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_treino.sum()/len(y_treino), y_val.sum()/len(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consideração da base parcial, com o uso do filtro de IV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Somente as variáveis com IV entre 0.1 e 0.5\n",
    "colunas_IV = ['used_pin_number','online_order','log_DFH_padro']\n",
    "\n",
    "X_treino_IV = treino[colunas_IV]\n",
    "X_val_IV = val[colunas_IV]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criação do experimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#experiment = mlflow.create_experiment(name = 'Modelos',\n",
    "#                                      artifact_location = 'Artf_Modelos',\n",
    "#                                      tags = {'Environment': 'Development', 'Version': '1.0.0'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'189457669412080989'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'189457669412080989'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment = mlflow.set_experiment(experiment_id = '189457669412080989')\n",
    "experiment.experiment_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função objetivo para ser minimizada e encontrar o melhor conjunto de hiperparâmetros com o uso de validação cruzada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_objetivo_CV(parametros, modelo, folds, expr, X, y):\n",
    "    # função objetivo para \"minimizar\", mas dependendo da métrica de interesse, na realidade, é maximizar \n",
    "    # parametros é o espaço paramétrico a ser explorado\n",
    "    # expr é uma string que representa o id do experimento que foi criado\n",
    "    # modelo é uma string de qual modelo será rodado: Random Forest ou XGBoost\n",
    "    # folds é um int que diz quantos folds de validação serão usados\n",
    "    # X e y são as bases que serão aplicadas o cross-validation\n",
    "\n",
    "    # O output é o valor do score a ser minimizado/maximizado\n",
    "    \n",
    "    with mlflow.start_run(nested = True, experiment_id=expr) as run:\n",
    "\n",
    "        SKF = StratifiedKFold(n_splits = folds, shuffle=True, random_state=1234)\n",
    "\n",
    "        if modelo == 'RF':\n",
    "            clf = RandomForestClassifier(**parametros) \n",
    "            clf.fit(X, y)\n",
    "        elif modelo == 'XGB':\n",
    "            clf = xgboost.XGBClassifier(**parametros)\n",
    "            clf.fit(X, y)\n",
    "        \n",
    "        score = cross_val_score(estimator = clf, X = X, y = y, cv = SKF, scoring='neg_log_loss').mean()\n",
    "\n",
    "        # Log de parâmetros e métricas\n",
    "\n",
    "        mlflow.log_params(clf.get_params())\n",
    "        mlflow.log_metric('average_precision_cv', cross_val_score(estimator = clf, X = X, y = y, cv = SKF, scoring='average_precision').mean())\n",
    "        mlflow.log_metric('roc_auc_cv', cross_val_score(estimator = clf, X = X, y = y, cv = SKF, scoring='roc_auc').mean())\n",
    "        mlflow.log_metric('neg_brier_score_cv', cross_val_score(estimator = clf, X = X, y = y, cv = SKF, scoring='neg_brier_score').mean())\n",
    "        mlflow.log_metric('neg_log_loss_cv', cross_val_score(estimator = clf, X = X, y = y, cv = SKF, scoring='neg_log_loss').mean())\n",
    "        \n",
    "        signature = infer_signature(X, clf.predict_proba(X))\n",
    "        mlflow.sklearn.log_model(clf, signature=signature, artifact_path='modelo')\n",
    "\n",
    "    return -score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest - Base Full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hugo/Documents/Git_GitHub/Estudo_Fraude_CC/vFraude_CC/lib/python3.12/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    with mlflow.start_run(run_name = 'Base_RF_Base_Full', experiment_id = experiment.experiment_id) as run: \n",
    "\n",
    "        rf = RandomForestClassifier()\n",
    "        rf.fit(X_treino, y_treino)\n",
    "\n",
    "        # Log dos parâmetros do modelo\n",
    "        mlflow.log_params(rf.get_params())\n",
    "\n",
    "        # Log das métricas na base de TREINO\n",
    "        mlflow.log_metric('AUC_PR_Treino', average_precision_score(y_treino, rf.predict_proba(X_treino)[:,1]))\n",
    "        mlflow.log_metric('AUC_ROC_Treino', roc_auc_score(y_treino, rf.predict_proba(X_treino)[:,1]))\n",
    "        mlflow.log_metric('BS_Treino', brier_score_loss(y_treino, rf.predict_proba(X_treino)[:,1]))\n",
    "        mlflow.log_metric('Log_Loss_Treino', log_loss(y_treino, rf.predict_proba(X_treino)[:,1], normalize=True))\n",
    "\n",
    "        # OBS: o ponto de corte utilizado é o 0.5 (ainda não otimizamos esse ponto)\n",
    "        #mlflow.log_metric('F1_Treino', f1_score(y_treino, rf.predict(X_treino)))\n",
    "        #mlflow.log_metric('Precision_Treino', precision_score(y_treino, rf.predict(X_treino)))\n",
    "        #mlflow.log_metric('Recall_Treino', recall_score(y_treino, rf.predict(X_treino)))\n",
    "        #mlflow.log_metric('Acuracia_Treino', accuracy_score(y_treino, rf.predict(X_treino)))\n",
    "\n",
    "        # Log das métricas na base de VALIDAÇÃO\n",
    "        mlflow.log_metric('AUC_PR_Val', average_precision_score(y_val, rf.predict_proba(X_val)[:,1]))\n",
    "        mlflow.log_metric('AUC_ROC_Val', roc_auc_score(y_val, rf.predict_proba(X_val)[:,1]))\n",
    "        mlflow.log_metric('BS_Val', brier_score_loss(y_val, rf.predict_proba(X_val)[:,1]))\n",
    "        mlflow.log_metric('Log_Loss_Val', log_loss(y_val, rf.predict_proba(X_val)[:,1], normalize=True))\n",
    "\n",
    "        # OBS: o ponto de corte utilizado é o 0.5 (ainda não otimizamos esse ponto)\n",
    "        #mlflow.log_metric('F1_Val', f1_score(y_val, rf.predict(X_val)))\n",
    "        #mlflow.log_metric('Precision_Val', precision_score(y_val, rf.predict(X_val)))\n",
    "        #mlflow.log_metric('Recall_Val', recall_score(y_val, rf.predict(X_val)))\n",
    "        #mlflow.log_metric('Acuracia_Val', accuracy_score(y_val, rf.predict(X_val)))\n",
    "        \n",
    "        # Log do schema das variáveis do modelo e do modelo\n",
    "        signature = infer_signature(X_treino, rf.predict_proba(X_treino))\n",
    "        mlflow.sklearn.log_model(rf, signature=signature, artifact_path='modelo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hugo/Documents/Git_GitHub/Estudo_Fraude_CC/vFraude_CC/lib/python3.12/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/25 [1:13:20<29:20:16, 4400.70s/trial, best loss: 0.023602231224237203]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hugo/Documents/Git_GitHub/Estudo_Fraude_CC/vFraude_CC/lib/python3.12/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    #test_imbalanced = [{0: len(y_treino2)/(2*np.bincount(y_treino2))[0], 1:len(y_teste2)/(2*np.bincount(y_teste2))[1]}, {0: 1, 1:1}]\n",
    "    \n",
    "    space = {\n",
    "        \"n_estimators\": hp.choice('n_estimators', np.arange(10, 500, dtype=int)),\n",
    "        \"max_depth\": hp.choice('max_depth', np.arange(10, 300, dtype=int)),\n",
    "        \"min_samples_leaf\": hp.choice('min_samples_leaf', np.arange(200, 500, dtype=int)),\n",
    "        \"min_samples_split\": hp.choice('min_samples_split', np.arange(200, 500, dtype=int)),\n",
    "        \"criterion\": hp.choice(\"criterion\", ['gini', 'entropy', 'log_loss']),\n",
    "        \"class_weight\": hp.choice(\"class_weight\", ['balanced', 'balanced_subsample', None]) \n",
    "    }\n",
    "    \n",
    "    with mlflow.start_run(run_name = 'Base_RF_Base_Full_CV', experiment_id=experiment.experiment_id) as run:\n",
    "        best_params = fmin(\n",
    "            fn = partial(\n",
    "                func_objetivo_CV,\n",
    "                expr = experiment.experiment_id,\n",
    "                modelo = 'RF',\n",
    "                X = X_treino,\n",
    "                y = y_treino,\n",
    "                folds = 3\n",
    "            ),\n",
    "            space = space,\n",
    "            algo = tpe.suggest,\n",
    "            max_evals = 25,\n",
    "            trials = Trials(),\n",
    "            timeout = 10\n",
    "        )\n",
    "\n",
    "        if best_params['criterion'] == 0:\n",
    "            best_params['criterion'] = 'gini'\n",
    "        elif best_params['criterion'] == 1:\n",
    "            best_params['criterion'] = 'entropy'\n",
    "        else:\n",
    "            best_params['criterion'] = 'log_loss'\n",
    "            \n",
    "\n",
    "        if best_params['class_weight'] == 0:\n",
    "            best_params['class_weight'] = 'balanced'\n",
    "        elif best_params['class_weight'] == 1:\n",
    "            best_params['class_weight'] = 'balanced_subsample'\n",
    "        else:\n",
    "            best_params['class_weight'] = None\n",
    "        \n",
    "        # Identificado o melhor conjunto de hiperparâmetros, treina o modelo com toda a base de treino e metrifica os escores na base de validação\n",
    "\n",
    "        clf = RandomForestClassifier(**best_params)\n",
    "        clf.fit(X_treino, y_treino)\n",
    "                   \n",
    "        mlflow.log_params(clf.get_params())\n",
    "        mlflow.log_metric('AUC_PR_Val', average_precision_score(y_val, clf.predict_proba(X_val)[:,1]))\n",
    "        mlflow.log_metric('Log_Loss_Val', log_loss(y_val, clf.predict_proba(X_val)[:,1], normalize=True))\n",
    "        mlflow.log_metric('AUC_ROC_Val', roc_auc_score(y_val, clf.predict_proba(X_val)[:,1]))\n",
    "        mlflow.log_metric('BS_Val', brier_score_loss(y_val, clf.predict_proba(X_val)[:,1]))\n",
    "\n",
    "        # Log das métricas na base de TREINO\n",
    "        mlflow.log_metric('AUC_PR_Treino', average_precision_score(y_treino, clf.predict_proba(X_treino)[:,1]))\n",
    "        mlflow.log_metric('AUC_ROC_Treino', roc_auc_score(y_treino, clf.predict_proba(X_treino)[:,1]))\n",
    "        mlflow.log_metric('BS_Treino', brier_score_loss(y_treino, clf.predict_proba(X_treino)[:,1]))\n",
    "        mlflow.log_metric('Log_Loss_Treino', log_loss(y_treino, clf.predict_proba(X_treino)[:,1], normalize=True))\n",
    "\n",
    "        signature = infer_signature(X_treino, clf.predict_proba(X_treino))\n",
    "        mlflow.sklearn.log_model(clf, signature=signature, artifact_path='modelo')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vFraude_CC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
